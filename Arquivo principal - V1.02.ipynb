{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AugustoCRX/bootcamp_blue/blob/main/Arquivo%20principal%20-%20V1.02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "9eZOMHv_5Bej"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "t7mLFg6o5IBH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hi9D5wpRbfNr"
      },
      "outputs": [],
      "source": [
        "def export_dataset():\n",
        "    #Lista de links (arquivos estão dentro do Google Sheets)\n",
        "    test_links = {\n",
        "        'link_01': 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQvClyfCtk8JD82zXYSipnN7iCJ0XG0V-z6tcII_14W7tQYPpLLOK45kKWLQf8TBfyRNhH9mlEXiowR/pub?output=csv',\n",
        "        'link_02': 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQq0fLn7Dkg0-Lg2i9FUD0iL-xLVHn1Gtorx8wLlA7flMftChIJf_PXgziaHshCnxlX52bZJZ2EKFsu/pub?output=csv'\n",
        "    }\n",
        "    train_links ={\n",
        "        'link_01':'https://docs.google.com/spreadsheets/d/e/2PACX-1vS2E4FyELPrgf1rPIeyh4lzQTOtftYYK6vyr7m5TN7cYDZTo4tLy1jZQ06mnnwo0NrJ5ZR5IOm2-ndN/pub?output=csv',\n",
        "        'link_02':'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-NHTDb71tp400NvyVObenotd8uUATgPgl4nlGwvqpwTTMoCmc8bH7YmyvmzBg_TcIAxoNkC0upfoe/pub?output=csv',       \n",
        "        'link_03':'https://docs.google.com/spreadsheets/d/e/2PACX-1vT_vX9ELHWxTt5kPrcZ8LchIXnBrd2QvbsuA5f_cHLWhaSvoa9DERR5W7oKE9489UzfFruwyek2XJvW/pub?output=csv',\n",
        "        'link_04':'https://docs.google.com/spreadsheets/d/e/2PACX-1vSi7JewvqVkONWiqbFWqyQjTOmtxrsEtZ4ArifmlCMELo9BAPw00BpnZ1BI9wx_ruE4nPbY3egzjEfx/pub?output=csv',\n",
        "        'link_05':'https://docs.google.com/spreadsheets/d/e/2PACX-1vTooCcyaoXnkazJ6HI95oc-Ll45cMY4qnjh6iIa9HVJfhTej2z9EBDVVHgplEhqLfegmeucud1mXMhS/pub?output=csv'\n",
        "    }\n",
        "   \n",
        "    #Download e leitura do arquivo de treinamento\n",
        "    temp_df_test = pd.DataFrame()\n",
        "    for i in test_links:\n",
        "        file_temp = pd.read_csv(test_links[i])\n",
        "        temp_df_test = pd.concat([temp_df_test,file_temp]) \n",
        "    temp_df_test.reset_index(drop=True, inplace=True)\n",
        "    temp_df_test.drop('Unnamed: 0',axis=1, inplace= True)\n",
        "\n",
        "    #Download e leitura do arquivo de teste\n",
        "    temp_df_train = pd.DataFrame()\n",
        "    for i in train_links:\n",
        "        file_temp = pd.read_csv(train_links[i])\n",
        "        temp_df_train = pd.concat([temp_df_train,file_temp]) \n",
        "    temp_df_train.reset_index(drop=True, inplace=True)\n",
        "    temp_df_train.drop('Unnamed: 0',axis=1, inplace= True)   \n",
        "   \n",
        "    return temp_df_test, temp_df_train\n",
        "\n",
        "test, train = export_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-Ulv2jbfNw"
      },
      "source": [
        "| Nome da coluna | Descrição |\n",
        "| :----: | :----: |\n",
        "| test_id | Numero identificador dos itens da lista |\n",
        "| name | Titulo da lista*|\n",
        "| item_condition_id | Numero da condição do item, varia de 1 a 5, sendo 1 a pior e 5 a melhor |\n",
        "| category_name | Categorias da lista |\n",
        "| brand_name | Nome da marca do item (existe nulos) |\n",
        "| price | Preço do produto |\n",
        "| shipping | Taxa de envio, pago por: 1 - pelo vendedor 0 - pelo comprador |\n",
        "| item_description | Descrição completa do item* |\n",
        "| date | Data |\n",
        "| stock | Estoque |\n",
        "\n",
        "*¹- Nessas colunas existe um valor chamado [rm], esse valor significa \"removed\" ou removido, significa que o preço (exemplo: $20) foi removido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_h6jHWGNbfNz"
      },
      "outputs": [],
      "source": [
        "train_vis = train[0:1000]\n",
        "test_vis = test[0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBi-YRXLbfN3",
        "outputId": "4492032a-1f53-487e-daf4-77bcdd1ce4a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1482535, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7E_4wHxbfN4",
        "outputId": "1cd10b68-b2f5-4b75-9d84-4bec33f0feb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1482535 entries, 0 to 1482534\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   train_id           1482535 non-null  int64  \n",
            " 1   name               1482535 non-null  object \n",
            " 2   item_condition_id  1482535 non-null  int64  \n",
            " 3   category_name      1476256 non-null  object \n",
            " 4   brand_name         850368 non-null   object \n",
            " 5   price              1482535 non-null  float64\n",
            " 6   shipping           1482535 non-null  int64  \n",
            " 7   item_description   1482531 non-null  object \n",
            " 8   date               1482535 non-null  object \n",
            " 9   stock              1482535 non-null  int64  \n",
            "dtypes: float64(1), int64(4), object(5)\n",
            "memory usage: 113.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frNeQWpC0jTy"
      },
      "source": [
        "##Limpeza de dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "bgpZJjKC5MMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971370ab-04ba-46fd-d645-f552c844126a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_data(df):\n",
        "  # droping null categories names and brands names(around 3000 values)\n",
        "  dropnull = df[df.category_name.isnull() & df.brand_name.isnull()].index\n",
        "  df = df.drop(dropnull, axis=0).reset_index(drop=True)\n",
        "  \n",
        "  # replace null values to \"Other\" df['category_name'] = df['category_name'].fillna(\"Other\")\n",
        "  df['category_name'] = df['category_name'].fillna(\"Other\")\n",
        "  \n",
        "  #have just 4 lines of null item description, i will remove them\n",
        "  df = df.dropna(subset = ['item_description']).reset_index(drop=True)\n",
        "  df = df.drop(columns = ['train_id'])\n",
        "  \n",
        "  #I will raplace all 629225 null values in \"train['brand_name']\" for other again, after we can looking again\n",
        "  df['brand_name'] = df['brand_name'].fillna(\"Other\")\n",
        "  \n",
        "  #replacing data 29-02-2018 for 28-02-2018\n",
        "  df['date'] =  df['date'].replace('29-2-2018','28-2-2018')\n",
        "  \n",
        "  #Creating new dates columns\n",
        "  df['date2'] = pd.to_datetime(df['date'], errors='coerce')    #corrige os erros com os valores das datas de nascimento, adequa para DateTime\n",
        "  df['day'] = df['date2'].dt.day\n",
        "  df['month'] = df['date2'].dt.month\n",
        "  df['year'] = df['date2'].dt.year\n",
        "\n",
        "  return df\n",
        "\n",
        "train = clear_data(train)"
      ],
      "metadata": {
        "id": "EZhQklQ_3uVx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = train['item_description']\n",
        "name_2 = train['name']"
      ],
      "metadata": {
        "id": "tC3EYEVl5OtK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloads necessários para rodar o código abaixo\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "DCFl9pd45Q8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035d179a-03a0-4753-9315-b49fac5ddf11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# funcao para tratar cada palavra e remover stopwords\n",
        "def processamento(tokens):\n",
        "    \n",
        "    token_processado = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = lemmatizer.lemmatize(token)\n",
        "        \n",
        "        if token not in stop_words:\n",
        "            token = stemmer.stem(token)\n",
        "            token_processado.append(token)\n",
        "        \n",
        "    return token_processado\n",
        "\n",
        "# expressao regular para remover pontuacoes do texto da coluna \n",
        "documentos_descript = []\n",
        "for descript in description:\n",
        "    \n",
        "    # expressao regular para remover pontuacoes do texto item_description\n",
        "    descript = re.sub(r'[^\\w\\s]','', descript)\n",
        "    tokens = processamento(word_tokenize(descript))\n",
        "    \n",
        "    documentos_descript.append(' '.join(tokens))"
      ],
      "metadata": {
        "id": "0pOyNMtw5USk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# expressao regular para remover pontuacoes do texto da coluna name\n",
        "\n",
        "# não precisei rodar este código para chegar ao resultado acima, mas pode ser útil futuramente\n",
        "\n",
        "# documentos_name = []\n",
        "# for name_3 in name_2:\n",
        "    \n",
        "    \n",
        "#     sinopse = re.sub(r'[^\\w\\s]','', name_3)\n",
        "#     tokens = processamento(word_tokenize(name_3))\n",
        "    \n",
        "#     documentos_name.append(' '.join(tokens))"
      ],
      "metadata": {
        "id": "xE3eNL0P5X6W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criando a coluna documento_descript\n",
        "train['documentos_descript'] = documentos_descript"
      ],
      "metadata": {
        "id": "X4wcpD33JLtm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #remoção dos itens duplicados\n",
        "index_duplicated = train[train[['category_name', 'name','documentos_descript','date','price']].duplicated()].index\n",
        "train = train.drop(index_duplicated, axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-UzFBCR24l7b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Continuação"
      ],
      "metadata": {
        "id": "2E4KLC0R5bfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A function that takes in a dataframe and a column name as parameters.\n",
        "#It then queries the dataframe for rows where the column value is 0. \n",
        "#It then drops those rows from the dataframe and returns the dataframe.\n",
        "def clear_price0(dataframe,column):\n",
        "    x = dataframe.query(f'{column} == 0').index\n",
        "    dataframe.drop(x, inplace= True)\n",
        "    return dataframe\n",
        "train = clear_price0(train,'price')"
      ],
      "metadata": {
        "id": "U88hsRln5dng"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}