{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hi9D5wpRbfNr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def export_dataset():\n",
        "    #Lista de links (arquivos estão dentro do Google Sheets)\n",
        "    test_links = {\n",
        "        'link_01': 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQvClyfCtk8JD82zXYSipnN7iCJ0XG0V-z6tcII_14W7tQYPpLLOK45kKWLQf8TBfyRNhH9mlEXiowR/pub?output=csv',\n",
        "        'link_02': 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQq0fLn7Dkg0-Lg2i9FUD0iL-xLVHn1Gtorx8wLlA7flMftChIJf_PXgziaHshCnxlX52bZJZ2EKFsu/pub?output=csv'\n",
        "    }\n",
        "    train_links ={\n",
        "        'link_01':'https://docs.google.com/spreadsheets/d/e/2PACX-1vS2E4FyELPrgf1rPIeyh4lzQTOtftYYK6vyr7m5TN7cYDZTo4tLy1jZQ06mnnwo0NrJ5ZR5IOm2-ndN/pub?output=csv',\n",
        "        'link_02':'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-NHTDb71tp400NvyVObenotd8uUATgPgl4nlGwvqpwTTMoCmc8bH7YmyvmzBg_TcIAxoNkC0upfoe/pub?output=csv',       \n",
        "        'link_03':'https://docs.google.com/spreadsheets/d/e/2PACX-1vT_vX9ELHWxTt5kPrcZ8LchIXnBrd2QvbsuA5f_cHLWhaSvoa9DERR5W7oKE9489UzfFruwyek2XJvW/pub?output=csv',\n",
        "        'link_04':'https://docs.google.com/spreadsheets/d/e/2PACX-1vSi7JewvqVkONWiqbFWqyQjTOmtxrsEtZ4ArifmlCMELo9BAPw00BpnZ1BI9wx_ruE4nPbY3egzjEfx/pub?output=csv',\n",
        "        'link_05':'https://docs.google.com/spreadsheets/d/e/2PACX-1vTooCcyaoXnkazJ6HI95oc-Ll45cMY4qnjh6iIa9HVJfhTej2z9EBDVVHgplEhqLfegmeucud1mXMhS/pub?output=csv'\n",
        "    }\n",
        "   \n",
        "    #Download e leitura do arquivo de treinamento\n",
        "    temp_df_test = pd.DataFrame()\n",
        "    for i in test_links:\n",
        "        file_temp = pd.read_csv(test_links[i])\n",
        "        temp_df_test = pd.concat([temp_df_test,file_temp]) \n",
        "    temp_df_test.reset_index(drop=True, inplace=True)\n",
        "    temp_df_test.drop('Unnamed: 0',axis=1, inplace= True)\n",
        "\n",
        "    #Download e leitura do arquivo de teste\n",
        "    temp_df_train = pd.DataFrame()\n",
        "    for i in train_links:\n",
        "        file_temp = pd.read_csv(train_links[i])\n",
        "        temp_df_train = pd.concat([temp_df_train,file_temp]) \n",
        "    temp_df_train.reset_index(drop=True, inplace=True)\n",
        "    temp_df_train.drop('Unnamed: 0',axis=1, inplace= True)   \n",
        "   \n",
        "    return temp_df_test, temp_df_train\n",
        "\n",
        "test, train = export_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-Ulv2jbfNw"
      },
      "source": [
        "| Nome da coluna | Descrição |\n",
        "| :----: | :----: |\n",
        "| test_id | Numero identificador dos itens da lista |\n",
        "| name | Titulo da lista*|\n",
        "| item_condition_id | Numero da condição do item, varia de 1 a 5, sendo 1 a pior e 5 a melhor |\n",
        "| category_name | Categorias da lista |\n",
        "| brand_name | Nome da marca do item (existe nulos) |\n",
        "| price | Preço do produto |\n",
        "| shipping | Taxa de envio, pago por: 1 - pelo vendedor 0 - pelo comprador |\n",
        "| item_description | Descrição completa do item* |\n",
        "| date | Data |\n",
        "| stock | Estoque |\n",
        "\n",
        "*¹- Nessas colunas existe um valor chamado [rm], esse valor significa \"removed\" ou removido, significa que o preço (exemplo: $20) foi removido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DjM-0U9CbfNy"
      },
      "outputs": [],
      "source": [
        "#o rm também foi adicionado em descrições completas, visualizar arquivo fixado no discord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u0cLcri7bfNz"
      },
      "outputs": [],
      "source": [
        "#existem valores repitidos na coluna brand_name (exemplo: adidas e adidas NEO, as duas são a mesma coisa)\n",
        "#necessário tratar esses dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_h6jHWGNbfNz"
      },
      "outputs": [],
      "source": [
        "train_vis = train[0:1000]\n",
        "test_vis = test[0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9NrzAFhwbfN0"
      },
      "outputs": [],
      "source": [
        "test1 = train.query(\"name == '[rm]'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmDt_wRYbfN0"
      },
      "outputs": [],
      "source": [
        "test2 = train.query(\"item_description == '[rm]'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SA3nL-4bfN1",
        "outputId": "66a60a63-d106-4768-b6da-0c7381d4f9f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    640290\n",
              "3    432140\n",
              "2    375731\n",
              "4     31987\n",
              "5      2387\n",
              "Name: item_condition_id, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['item_condition_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PapgtTiQbfN2"
      },
      "outputs": [],
      "source": [
        "#category_name\n",
        "#lista de categorias do nome da lista\n",
        "#divido por caracteres especiais\n",
        "#necessário limpeza para avaliação, talvez dividir em lista ou dummmies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBi-YRXLbfN3",
        "outputId": "ab020418-ed31-4805-8552-1982f3af6d43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1482535, 10)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APaePSycbfN3",
        "outputId": "16c6e590-55e9-411b-dc6c-9f1ffb927cde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4543,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_array = train['brand_name'].drop_duplicates().unique()\n",
        "train['brand_name'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7E_4wHxbfN4",
        "outputId": "293a314a-5b52-4772-95fd-a76bff62cf05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1482535 entries, 0 to 1482534\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   train_id           1482535 non-null  int64  \n",
            " 1   name               1482535 non-null  object \n",
            " 2   item_condition_id  1482535 non-null  int64  \n",
            " 3   category_name      1476256 non-null  object \n",
            " 4   brand_name         850368 non-null   object \n",
            " 5   price              1482535 non-null  float64\n",
            " 6   shipping           1482535 non-null  int64  \n",
            " 7   item_description   1482531 non-null  object \n",
            " 8   date               1482535 non-null  object \n",
            " 9   stock              1482535 non-null  int64  \n",
            "dtypes: float64(1), int64(4), object(5)\n",
            "memory usage: 113.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P3FgNuJyiiXw"
      },
      "outputs": [],
      "source": [
        "# Remove special caracters from a list and return itself\n",
        "def remove_especial_caracters(dataframe_column):\n",
        "    complete_array = []\n",
        "    for n in range(len(dataframe_column)):\n",
        "        array = str(dataframe_column[n]).split('/')\n",
        "        for i in range(len(array)):\n",
        "            x = str(array[i])\n",
        "            complete_array.append(x)\n",
        "    return complete_array\n",
        "\n",
        "train_frame = remove_especial_caracters(train['category_name'])\n",
        "test_frame = remove_especial_caracters(test['category_name'])\n",
        "\n",
        "unique, counts = np.unique(test_frame, return_counts=True)\n",
        "frame = pd.DataFrame(np.stack((unique, counts), axis = 1), columns= ['Category name', 'Count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PU4vpLJtigoZ"
      },
      "outputs": [],
      "source": [
        "#puttting in order\n",
        "frame['Count'] = pd.to_numeric(frame['Count'])\n",
        "\n",
        "frame.sort_values(by=['Count'], inplace=True, ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Vp-vXZo_idc4",
        "outputId": "1a7a9da0-4f8d-48c7-e72a-8ba754aee5c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>Women</td>\n",
              "      <td>319042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Beauty</td>\n",
              "      <td>97265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>Kids</td>\n",
              "      <td>80299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Athletic Apparel</td>\n",
              "      <td>62669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>Shoes</td>\n",
              "      <td>61731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>Daily &amp; Travel items</td>\n",
              "      <td>5406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>One-Pieces</td>\n",
              "      <td>5390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>Rings</td>\n",
              "      <td>5121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>Skirts</td>\n",
              "      <td>5029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Collectibles</td>\n",
              "      <td>5025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Category name   Count\n",
              "898                 Women  319042\n",
              "80                 Beauty   97265\n",
              "463                  Kids   80299\n",
              "34       Athletic Apparel   62669\n",
              "721                 Shoes   61731\n",
              "..                    ...     ...\n",
              "251  Daily & Travel items    5406\n",
              "575            One-Pieces    5390\n",
              "684                 Rings    5121\n",
              "731                Skirts    5029\n",
              "221          Collectibles    5025\n",
              "\n",
              "[78 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frame.loc[frame['Count']>5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dfN_q11ficzi",
        "outputId": "a5703f60-7a47-423c-9f04-455dbb0a61e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Women' 'Beauty' 'Kids' 'Athletic Apparel' 'Shoes' 'Electronics' 'Makeup'\n",
            " 'Other' 'Tops & Blouses' 'Men' 'Home' 'Jewelry' 'Pants, Tights, Leggings'\n",
            " 'Toys' 'Dresses' 'Cell Phones & Accessories' 'Face' 'T-Shirts'\n",
            " 'Vintage & Collectibles' \"Women's Handbags\" \"Women's Accessories\" 'Jeans'\n",
            " 'Video Games & Consoles' 'Sweaters' 'Underwear' 'Lips' 'Games' 'Handmade'\n",
            " 'Skin Care' 'Athletic' 'Eyes' 'Sports & Outdoors' 'Home Décor'\n",
            " 'Coats & Jackets' 'Fragrance' 'Cases, Covers & Skins' 'Shorts'\n",
            " 'Kitchen & Dining' 'Bras' 'Tops' 'Tank, Cami' 'Swimwear' 'Blouse'\n",
            " 'Above Knee, Mini' 'Boots' 'Necklaces' 'Makeup Palettes'\n",
            " \"Men's Accessories\" 'Girls 2T-5T' 'Accessories' 'Girls 0-24 Mos'\n",
            " 'Shirts & Tops' 'Girls (4+)' 'Shoulder Bag' 'Fashion Sneakers' 'T-shirts'\n",
            " 'Sandals' 'Boys 0-24 Mos' 'Tops & T-Shirts' 'Wallets' 'Boys (4+)'\n",
            " 'Knee-Length' 'Boys 2T-5T' 'Bracelets' 'Dolls & Accessories'\n",
            " 'Slim, Skinny' 'Home Décor Accents' 'Tools & Accessories' 'Two-Piece'\n",
            " 'Action Figures & Statues' 'Hats' 'Media' 'Earrings'\n",
            " 'Daily & Travel items' 'One-Pieces' 'Rings' 'Skirts' 'Collectibles'\n",
            " 'Office supplies' 'Body' 'Cell Phone Accessories'\n",
            " 'Coffee & Tea Accessories' 'Hooded' 'Jackets' 'Pants' 'Totes & Shoppers'\n",
            " 'Sunglasses' 'TV, Audio & Surveillance' 'Messenger & Crossbody'\n",
            " 'Sports Bras' 'Cell Phones & Smartphones' 'Panties' 'Cardigan' 'Clothing'\n",
            " 'Sweats & Hoodies' 'Crewneck' 'Tunic' 'Exercise' 'Books' 'Toy' 'Watches'\n",
            " 'Hair Care' 'DVD' 'Bath & Body' 'Bottoms' 'Pumps' 'Computers & Tablets'\n",
            " 'Makeup Brushes & Tools' 'Boot Cut' 'Arts & Crafts' 'Leggings'\n",
            " 'Trading Cards' 'nan' 'Tracksuits & Sweats' 'Paper Goods' 'Fan Shop'\n",
            " 'Bags and Purses' 'Nails' 'Antique' 'Bath' 'Makeup Sets'\n",
            " 'Stuffed Animals & Plush' 'Personal Care' 'Full-Length' 'Bedding' 'Flats'\n",
            " 'Loafers & Slip-Ons' 'Dining & Entertaining' 'Action Figure'\n",
            " 'Hair Accessories' 'Shipping Supplies' 'Seasonal Décor' 'Home Fragrance'\n",
            " 'Socks' 'Backpack Style' 'Headphones' 'Feeding' 'Fitness accessories'\n",
            " 'Outdoors' 'Sticker' 'Consoles' 'Top & T-shirts' 'Cameras & Photography'\n",
            " 'Pet Supplies' 'Jerseys' 'Hair Styling Tools' 'Storage & Organization'\n",
            " 'Hoodie' 'Cosmetic Bags' 'One-Piece' 'Button Down Shirt' 'Diapering'\n",
            " 'Fleece Jacket' 'NFL' 'Maternity' 'Cables & Adapters' 'Knit Top'\n",
            " 'Asymmetrical Hem' 'Literature & Fiction' 'Animation' 'Straight, Pencil'\n",
            " 'Full Zip' 'Tablet' 'iPad' 'Apparel' 'Gear' 'Windbreaker'\n",
            " 'Sweatshirt, Pullover' 'Candles & Home Scents' 'Maxi' 'Sports'\n",
            " 'Health Care' 'Hobbies' 'Mini' 'Vest' 'Home Appliances' 'Lingerie'\n",
            " 'Scarves & Wraps' 'Dogs' 'Casual Pants' 'Belts' 'Brushes & Applicators'\n",
            " 'Automotive' 'Styling Products' 'Kitchen Utensils & Gadgets'\n",
            " 'Cleaning Supplies' 'Polo, Rugby' 'Candles & Holders' 'Costume' 'Satchel'\n",
            " 'Christmas' 'Keychain' 'Video Game' 'Building Toys' 'Book' 'Blu-Ray'\n",
            " 'Halloween' 'Screen Protectors' 'Team Sports' 'Chargers & Cradles'\n",
            " 'Housewares' 'Portable Audio & Accessories' 'Slippers' 'eBook Readers'\n",
            " 'Backpacks & Carriers' 'Headsets' 'Hiking & Camping'\n",
            " 'Baby & Toddler Toys' 'Glass' 'Button-Front' 'Fitness technology' 'Purse'\n",
            " 'Suits & Blazers' 'G-Strings & Thongs' 'Bottle-Feeding' 'Serving'\n",
            " 'Classic, Straight Leg' 'Laptops & Netbooks' 'School Supplies'\n",
            " 'Shampoo & Conditioner Sets' 'Backpacks, Bags & Briefcases'\n",
            " 'Capris, Cropped' 'Jean Jacket' 'Nursery' 'Household Cleaners'\n",
            " 'Blankets & Throws' 'Jewelry Boxes & Organizers' 'CD'\n",
            " 'Track & Sweat Pants' 'Capri, Cropped' 'Straight Leg' 'Digital Cameras'\n",
            " 'Sports Nutrition' \"Children's Books\" 'Others' 'Children' 'Dress Pants'\n",
            " 'Halter' 'Blazer' 'Figurine' 'Supplies' 'Sweater' 'Education & Teaching'\n",
            " 'Hair & Scalp Treatments' 'Handbag' 'Lanyard' 'Bakeware' 'Artwork' 'Hair'\n",
            " 'Doll' 'Diaper Bags' 'Motorcycle' 'Video Gaming Merchandise' 'Comics'\n",
            " 'Dress Up & Pretend Play' 'Disposable Diapers' 'Skirts, Skorts & Dresses'\n",
            " 'Sets' 'Boys' 'Wine, Beer & Beverage Coolers' 'Learning & Education'\n",
            " 'Camera & Photo Accessories' 'MLB' 'Puffer' 'Gadgets' 'Scrapbooking'\n",
            " 'NCAA' 'Musical instruments' 'Wristlet' 'Beach Accessories'\n",
            " 'eBook Access' 'Charm' 'Toy Remote Control & Play Vehicles' 'Mid-Calf'\n",
            " 'Party Supplies' 'Components & Parts' 'Car Seats & Accessories'\n",
            " 'Film Photography' 'Cover-Ups' 'Pregnancy & Maternity' 'Music' 'V-Neck'\n",
            " 'Kitchen Appliances' 'Mules & Clogs' 'Decorative Pillows' 'Sun'\n",
            " 'Souvenir' 'Sheets & Pillowcases' 'Bathroom Accessories' 'Writing'\n",
            " 'Medical Supplies & Equipment' 'Tumbler' 'Vinyl' 'Mug' 'Boyfriend'\n",
            " 'Pacifiers & Accessories' 'Photo Albums & Frames' 'Electronics for Kids'\n",
            " 'Khakis, Chinos' 'Scrubs & Body Treatments' 'Cleansers'\n",
            " 'Posters & Prints' 'Golf' 'Cloth Diapers' 'A-Line' \"Kids' Home Store\"\n",
            " 'Flare' 'Hands & Nails' 'Patch' 'Bathing & Skin Care' 'Art' 'Home Decor'\n",
            " 'Lamps& Accessories' 'Tapestries' 'Polo Shirt' 'Casual Shorts' 'Corset'\n",
            " 'Puzzles' 'Exterior Accessories' 'Hair Color' 'Peacoat' 'Ceramic' 'Cargo'\n",
            " 'Drives, Storage & Media' 'Storage & Containers' 'Breastfeeding'\n",
            " 'Organization' 'Weddings' 'Military' 'Wrap' 'Baseball & Softball'\n",
            " 'Tools & Equipment' 'Calendars' 'Dance' 'Ballet' 'Car' 'NBA'\n",
            " 'Comforters & Sets' 'Cowl Neck' 'Window Treatments' 'Ink & Toner'\n",
            " 'Cookware' 'Vest, Sleeveless' 'Health & Baby Care' 'Girls' 'Collared'\n",
            " 'Footwear' 'Nail Tools' 'Soccer' 'Car Audio, Video & GPS' 'Trench'\n",
            " 'Bags & Cases' 'Strollers' 'Cleats' 'Pendant' 'Yoga & Pilates' 'Mirrors'\n",
            " 'Safety' 'Poncho' 'Sports & Outdoor Play' 'Dress Shirts' 'Tank'\n",
            " 'Breastfeeding Pillows & Stools' 'Pleated' 'Kitchen & Table Linens'\n",
            " 'Baby' 'Ring' 'Cards' 'Pant Suit' 'Scoop Neck' 'Makeup Remover'\n",
            " \"Kids' Room Décor\" 'Clothing & Closet Storage' 'Ties' 'Air Fresheners'\n",
            " 'Raincoat' 'Football' 'Fishing' 'Conditioners' 'Indoor' 'Outdoor Games'\n",
            " 'Bowl' 'Televisions' 'Skateboard' 'Home Speakers & Subwoofers' 'Necklace'\n",
            " 'Shampoos' 'Brooch' 'Luggage' 'Oxfords' 'Basic Supplies' 'Full Skirt'\n",
            " 'Overalls' 'Holidays' 'VHS' 'Swim Trunks' 'Feet' 'Food'\n",
            " 'Interior Accessories' 'Cup' 'Household Supplies' 'Hobo'\n",
            " 'Turtleneck, Mock' 'Small Appliances' 'Medical Books' 'Styling Tools'\n",
            " 'Networking & Connectivity' 'Relaxed' 'Lights & Lighting Accessories'\n",
            " 'Clutch' 'Car Electronics & Accessories'\n",
            " 'Decorative Pillows, Inserts & Covers' 'Swings, Jumpers & Bouncers'\n",
            " 'Bathing Accessories' 'Flight' 'Bomber' 'Bike & Skate' 'Clocks'\n",
            " 'Religion & Spirituality' 'Family Planning Tests' 'Car Seats' 'Tote'\n",
            " 'Eyewear' 'Wine Accessories' 'Decorations' 'Racks, Shelves & Drawers'\n",
            " 'Electronic' 'Bracelet' 'Parka' 'Golf Apparel' 'Vintage'\n",
            " 'Printers, Scanners & Supplies' 'Pinback Button' 'Wipes & Holders'\n",
            " 'Snowboard' 'Stationery' 'Sci-Fi, Fantasy' 'Gloves' 'Monitors' 'Animal'\n",
            " 'Valentine' 'Batteries' 'Painting' 'Duvet Covers & Sets' 'Sweatercoat'\n",
            " 'Athletic Training' 'Crochet' 'Pets' 'Water Sports' 'Waxing' 'Paintings'\n",
            " 'Turtleneck' 'Baskets' 'Wall Decor' 'DVD & Blu-ray Players' 'Needlecraft'\n",
            " \"Kids' Bedding\" 'Change Purse' \"Men's Golf Clubs\" 'Thermal Underwear'\n",
            " 'Pin' 'Easter' 'Area Rugs & Pads' 'Camera' 'Wool' 'Bottles'\n",
            " 'Washcloths & Towels' 'Baskets & Bins' 'Vacuums & Floor Care' 'Furniture'\n",
            " 'Drawings' 'Christian Books & Bibles' 'Bead' 'Game'\n",
            " 'Water Coolers & Filters' 'Baby Seats' 'Thanksgiving' 'Vases'\n",
            " 'Business & Money' 'Magazines' 'Arts & Photography' 'Wall Hanging'\n",
            " 'Towels' 'Work & Safety' 'Outdoor' 'GPS Units & Equipment' 'Cage'\n",
            " 'Backpack' 'Fabric' 'Bathing Tubs & Seats' 'Stationery & Party Supplies'\n",
            " 'Patterns' 'Kitchen Knives & Cutlery Accessories' 'Novelty & Gag Toys'\n",
            " 'Instrument Accessories' 'Nursery Décor' 'NHL' 'Desktops & All-In-Ones'\n",
            " 'Lifestyle & Cultures' 'Lenses & Filters' 'Guitars' 'Glassware'\n",
            " 'Microphones & Accessories' 'Reference' 'Baby & Child Care' 'Quilts'\n",
            " 'Boxing & MMA' 'Jacket' 'Yarn' 'Tripods & Supports' 'Hat' 'Board Shorts'\n",
            " 'Knitting' 'Science & Math' 'Sewing' 'Basketball' 'Baby Gyms & Playmats'\n",
            " 'Home Surveillance' 'Dress' 'Paper Ephemera' 'Leg Warmers'\n",
            " 'Potty Training' 'Hip Bag' 'Camcorders' 'Pouch' 'Golf Balls'\n",
            " 'Shopping Cart Covers' 'Bed Pillows' 'Strength training'\n",
            " 'Car Stereos & Components' 'Geekery' 'Woodworking' 'Tshirt'\n",
            " 'Knitting Supplies' 'Teething Relief' 'Shrug' 'Shirt' 'Asymmetrical'\n",
            " 'Fans' 'Watch' 'Porcelain' 'Prenatal Monitoring Devices'\n",
            " 'Changing Pads & Covers' 'Motorcycle & Powersports' 'Volleyball' 'Denim'\n",
            " 'Salt and Pepper Shakers' '100 Years or Older' 'Journal'\n",
            " 'Hair Loss Products' 'Toothbrushes' 'Stringed Instruments' 'Epilators'\n",
            " 'Collar' 'Travel Systems' 'Two Button' 'Rainwear' 'Cookbook'\n",
            " 'Tennis & Racquets' 'Print' 'Gift Wrap' 'Biographies & Memoirs'\n",
            " 'Laundry Storage & Organization' 'Snowsuits & Bibs'\n",
            " 'Highchairs & Booster Seats' 'Humidifiers'\n",
            " \"Kids' Furniture, Décor & Storage\" 'Potties & Seats' 'Baguette' 'Fiction'\n",
            " 'Keyboards' 'Lacrosse' 'Magic' 'DJ, Electronic Music & Karaoke'\n",
            " 'Sets & Kits' 'Leather' 'Tweezers' 'Mopping' 'Dress - Flat Front'\n",
            " 'Food Service Equipment & Supplies' 'Corduroys' 'Strategy Guides'\n",
            " 'GPS Accessories & Mounts' 'Suits' 'Mattress Pads' 'Ceramics and Pottery'\n",
            " 'Linen' 'Notebook' 'Home Audio' 'Thermometers' 'Skirt Suit' 'Henley'\n",
            " 'Space Heaters' 'Custom' 'Stamps' 'Blazers & Sport Coats' 'Wide Leg'\n",
            " '50 To 75 Years' 'Diaper Pails & Refills' 'Hockey' 'Track Jacket'\n",
            " 'History' 'Humidifiers & Vaporizers' 'Hawaiian' 'Binoculars & Telescopes'\n",
            " 'Harnesses & Leashes' 'Baggy, Loose' 'Laptop'\n",
            " 'Tricycles, Scooters & Wagons' 'Scarf' 'Garment Steamers' 'Birthday'\n",
            " 'Candles' 'Carpenter' 'Cabochon' 'Teethers' 'Sculptures' 'Personalized'\n",
            " 'Cabinet Locks & Straps' 'Polo' 'Religious' 'Drums & Percussion'\n",
            " 'Wind & Woodwind Instruments' 'Walkers' 'Board, Surf' 'Books and Zines'\n",
            " 'Ornaments' 'Amplifiers & Effects' 'Science' 'Apron' 'Gift Sets' 'Vests'\n",
            " 'Formal' '75 To 100 Years' 'Studio Recording Equipment' 'Buckle'\n",
            " 'Track & Sweat Suits' 'Irons & Ironing Boards' 'Soaps & Cleansers'\n",
            " 'Living Room Furniture' 'Bathroom Storage & Organization'\n",
            " 'Lighting & Studio' 'All Other Sports' 'Cake Toppers'\n",
            " 'Dolls and Miniatures' 'Cape' 'Swim Briefs' 'Playards' 'Paper Towels'\n",
            " 'Tape' 'Car Speakers & Systems' 'Teacup' 'Cross Stitch' 'Magnets'\n",
            " 'Replacement Parts & Tools' 'Car Care' 'Politics & Social Sciences'\n",
            " 'Candle Holder' 'Bedroom Furniture' 'Training Pants' 'Skirt' 'Radio'\n",
            " 'Other Accessories' 'Crafting' 'Outdoor Safety' 'Bowls' 'Paper'\n",
            " 'Pet Lover' 'Favors' 'Air Conditioners' 'Nonfiction' 'Puzzle' 'Planter'\n",
            " 'Printmaking' 'Nasal Aspirators' 'Maternity Pillows' 'Bouquets'\n",
            " 'Bedspreads & Coverlets' 'Coaster' 'Air Purifiers'\n",
            " 'Grooming & Healthcare Kits' 'Bath Rugs' \"Kids' Furniture\" 'Signs'\n",
            " 'Shampoo Plus Conditioner' 'Shawl' 'Kitchen' 'Car Video' 'Box'\n",
            " 'Home Office Furniture' 'Comic' 'Varsity' 'Poetry' 'Baseball'\n",
            " 'Trash Bags' 'Shams, Bed Skirts & Bed Frame Draperies'\n",
            " 'Brass Instruments' 'Wallet' 'Accessory' 'Dress Shorts' 'Embroidery'\n",
            " 'Golf Shoes' 'Plate' 'Lighting' 'Powders & Lotions'\n",
            " 'Automotive Enthusiast Merchandise' 'Instructional' 'Magnet'\n",
            " 'Cream and Sugar Set' 'Dress - Pleat' \"St Patrick's\" 'Shampoo'\n",
            " 'Dress Suit' 'Gates & Doorways' 'Teapot' 'Car Subwoofers' 'Basket' 'Tray'\n",
            " 'Band & Orchestra' 'Inflatable Beds' 'Activity Centers & Entertainers'\n",
            " 'Tires & Wheels' 'Three Button' 'Golf Bags' 'Mixed Media' 'Small Animal'\n",
            " 'Papermaking' 'Bookmark' 'Travel Beds' 'Boating' 'Tiered' 'Postcard'\n",
            " 'Vase' 'Performance Parts & Accessories' 'Leash' 'Refrigerators' 'Block'\n",
            " 'Home Brewing & Wine Making' 'Kitchen Storage & Organization' 'Poster'\n",
            " 'Biography' 'Health' 'Replacement Parts' 'Frame' 'Dusting' 'Slipcovers'\n",
            " 'Sleep Positioners' 'Travel Bathing Kits' 'Gadget' 'Guest Books'\n",
            " 'Pillows' 'Pillow' 'Other Furniture' 'Bubble' 'Case' 'Photography'\n",
            " 'Telephone' 'Instrument' 'Lightweight' 'Peasant' 'Joggers' 'One Button'\n",
            " 'Miniature' 'Finding' 'Washers & Dryers' 'Flashes & Flash Accessories'\n",
            " 'Pattern' 'Garage Storage & Organization' 'Compact' 'Blanket' 'Linens'\n",
            " 'Pillows & Stools' 'Dishes' 'Photographs' 'Toiletry Kits'\n",
            " 'Hair Perms & Texturizers' 'Cuff Links' 'How to' 'Beads' 'Graphic Design'\n",
            " 'Trash & Recycling' 'Bed' 'Scale Dollhouse Miniature'\n",
            " 'Home Entertainment Furniture' 'Invitations' 'Tag' 'Patriotic'\n",
            " 'Bath Linen Sets' 'Electrical Safety' 'Plush'\n",
            " 'Lithographs, Etchings & Woodcuts' 'Microwaves' 'Standard'\n",
            " 'Stained Glass' 'Action, Adventure' 'Bubble Bath' 'Button' 'Afghan'\n",
            " \"Kids' Bath\" 'Art Doll' 'Outerwear' 'Bathroom Safety'\n",
            " 'Paint, Body & Trim' 'Sport' 'Calendar' 'Brushes' 'Amigurumi' 'Planters'\n",
            " 'Car Security & Convenience' 'Toddler' 'Bed in a Bag' 'Needlepoint'\n",
            " 'Sponges' 'Belt' 'Handkerchief' 'Diaper Stackers & Caddies'\n",
            " 'Dinnerware Set' 'Sun Protection' 'Doormats' 'Home Bar Furniture'\n",
            " 'Just Married' 'Dehumidifiers' 'New Years' 'Illustration' \"New Year's\"\n",
            " 'Nail Care' 'Bowling' 'Patchwork' 'Album' 'Nursery Bedding' 'Origami'\n",
            " 'Videogame' 'Television' 'Fantasy' 'Decorating' 'Religion'\n",
            " 'Hair Coloring Tools' 'Equipment' 'Presentation' 'Fiber Art' 'Chair'\n",
            " 'Casserole' 'Storage Cabinets' 'Grooming' 'Flatware' 'Tandem' 'Horror'\n",
            " 'Carpenter, Utility' 'Playard Bedding' 'Four Button' 'Diaper Bag'\n",
            " 'Seat Covers' 'Seasonal' 'Double Breasted' 'Rails & Rail Guards'\n",
            " 'Bathroom Furniture Sets' 'Bathroom Shelves' 'Bathroom Furniture'\n",
            " 'Office' 'Hair Relaxers' 'Nursery Furniture' 'Educational'\n",
            " 'Track & Field' 'Entertaining' 'Entertainment' 'Rugs' 'Badminton'\n",
            " 'Beading' 'Felted' \"Women's Golf Clubs\" 'Figurines' 'Map' 'Scale Models'\n",
            " 'Garbage Disposals' 'Scifi' 'Advertisement' 'Zipper' 'Mirror'\n",
            " 'Oils & Fluids' 'Bedroom' 'Quilt' 'Carving' 'Cleaning' 'Changing Kits'\n",
            " 'Chain' 'Table' 'Trim' 'Boxes' 'Platter' 'Clock' 'Frames' 'Pitcher'\n",
            " 'Human Figure Doll' 'Humor' 'Illustrated' 'Butter Dish' 'Tuxedo'\n",
            " \"Kids' Flatware\" 'Step Stools' 'Historical, Military' 'Storage' 'Burning'\n",
            " 'Day of the Dead' 'Professional & Trade' 'Primitive' 'Pretend' 'Prams'\n",
            " 'Sweeping' 'Cotton & Swabs' 'Pot Holder' 'Computer' 'Kitchen Safety'\n",
            " 'Portraits' 'Collages' 'Freezers & Ice Makers']\n",
            "count       915\n",
            "unique      915\n",
            "top       Women\n",
            "freq          1\n",
            "Name: Category name, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Category name, Count]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#looking all categories names\n",
        "print(frame['Category name'].unique())\n",
        "print(frame['Category name'].describe())\n",
        "display (frame[frame['Category name'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Hn3FlnQ10gr9",
        "outputId": "9b45eed5-825c-4021-acf5-8834aa9ed9af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>Other</td>\n",
              "      <td>54003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Category name  Count\n",
              "579         Other  54003"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#looking for general categories\n",
        "frame[frame['Category name']==\"Other\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "YiNIdAA9rA7A",
        "outputId": "ae618ba5-d94e-4d68-ed1a-4b69723a7a46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category name</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>Others</td>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Category name  Count\n",
              "582        Others    654"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#looking for general categories\n",
        "frame[frame['Category name']==\"Others\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frNeQWpC0jTy"
      },
      "source": [
        "##Limpeza de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l_CCnXDg_6S",
        "outputId": "3b5adf96-dd61-4006-90db-189e3eae45ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1482535 entries, 0 to 1482534\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   train_id           1482535 non-null  int64  \n",
            " 1   name               1482535 non-null  object \n",
            " 2   item_condition_id  1482535 non-null  int64  \n",
            " 3   category_name      1476256 non-null  object \n",
            " 4   brand_name         850368 non-null   object \n",
            " 5   price              1482535 non-null  float64\n",
            " 6   shipping           1482535 non-null  int64  \n",
            " 7   item_description   1482531 non-null  object \n",
            " 8   date               1482535 non-null  object \n",
            " 9   stock              1482535 non-null  int64  \n",
            "dtypes: float64(1), int64(4), object(5)\n",
            "memory usage: 113.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "Ixv5EQLsfJaK",
        "outputId": "82031e0c-a173-494d-8ab1-246e793a9caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Men/Tops/T-shirts' 'Electronics/Computers & Tablets/Components & Parts'\n",
            " 'Women/Tops & Blouses/Blouse' ... 'Handmade/Jewelry/Clothing'\n",
            " 'Vintage & Collectibles/Supplies/Ephemera' 'Handmade/Pets/Blanket']\n",
            "count                                            1476256\n",
            "unique                                              1266\n",
            "top       Women/Athletic Apparel/Pants, Tights, Leggings\n",
            "freq                                               60092\n",
            "Name: category_name, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_id</th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>Bundle</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sizes and info of clothes can be found on thei...</td>\n",
              "      <td>17-4-2018</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>155</td>\n",
              "      <td>3 Nora Roberts Books</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>For aferg16.</td>\n",
              "      <td>16-1-2018</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>258</td>\n",
              "      <td>ACER Laptop</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Powers on, no screen display, no external dama...</td>\n",
              "      <td>19-8-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>984</td>\n",
              "      <td>AUTHENTIC BRWN MICHAEL KORS MAKEUP STAIN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael Kors</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>5-2-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1185</th>\n",
              "      <td>1185</td>\n",
              "      <td>Teenage Mutant Ninja Turtle Van/ Extras</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nickelodeon</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Teenage Mutant Ninja Turtle Van, April O'Neil ...</td>\n",
              "      <td>13-4-2018</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481249</th>\n",
              "      <td>1481249</td>\n",
              "      <td>Only For Erin. Do Not Buy</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>20-4-2018</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481750</th>\n",
              "      <td>1481750</td>\n",
              "      <td>American Eagle Jeggings</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American Eagle</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Worn a couple of time Size 4</td>\n",
              "      <td>12-10-2018</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482252</th>\n",
              "      <td>1482252</td>\n",
              "      <td>Bundle For All Honey :)</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>6-2-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482443</th>\n",
              "      <td>1482443</td>\n",
              "      <td>HOLD 14g Purple Prong Nipple Bars Rings</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14g Purple Prong Set Nipple Bars Rings [surgic...</td>\n",
              "      <td>20-3-2018</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482473</th>\n",
              "      <td>1482473</td>\n",
              "      <td>Puma Suede Emboss</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PUMA</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Worn Once!!! Great condition!!!</td>\n",
              "      <td>21-6-2018</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6279 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         train_id                                      name  \\\n",
              "122           122                                    Bundle   \n",
              "155           155                      3 Nora Roberts Books   \n",
              "258           258                               ACER Laptop   \n",
              "984           984  AUTHENTIC BRWN MICHAEL KORS MAKEUP STAIN   \n",
              "1185         1185   Teenage Mutant Ninja Turtle Van/ Extras   \n",
              "...           ...                                       ...   \n",
              "1481249   1481249                 Only For Erin. Do Not Buy   \n",
              "1481750   1481750                   American Eagle Jeggings   \n",
              "1482252   1482252                   Bundle For All Honey :)   \n",
              "1482443   1482443   HOLD 14g Purple Prong Nipple Bars Rings   \n",
              "1482473   1482473                         Puma Suede Emboss   \n",
              "\n",
              "         item_condition_id category_name      brand_name  price  shipping  \\\n",
              "122                      3           NaN             NaN   59.0         0   \n",
              "155                      3           NaN             NaN   10.0         1   \n",
              "258                      5           NaN             NaN   14.0         0   \n",
              "984                      4           NaN    Michael Kors   18.0         0   \n",
              "1185                     3           NaN     Nickelodeon    9.0         0   \n",
              "...                    ...           ...             ...    ...       ...   \n",
              "1481249                  3           NaN             NaN   31.0         0   \n",
              "1481750                  2           NaN  American Eagle   17.0         0   \n",
              "1482252                  3           NaN             NaN   40.0         0   \n",
              "1482443                  1           NaN             NaN   22.0         1   \n",
              "1482473                  2           NaN            PUMA   30.0         1   \n",
              "\n",
              "                                          item_description        date  stock  \n",
              "122      Sizes and info of clothes can be found on thei...   17-4-2018     25  \n",
              "155                                           For aferg16.   16-1-2018      2  \n",
              "258      Powers on, no screen display, no external dama...   19-8-2018      1  \n",
              "984                                     No description yet    5-2-2018      6  \n",
              "1185     Teenage Mutant Ninja Turtle Van, April O'Neil ...   13-4-2018      9  \n",
              "...                                                    ...         ...    ...  \n",
              "1481249                                 No description yet   20-4-2018     13  \n",
              "1481750                       Worn a couple of time Size 4  12-10-2018      5  \n",
              "1482252                                 No description yet    6-2-2018      1  \n",
              "1482443  14g Purple Prong Set Nipple Bars Rings [surgic...   20-3-2018     17  \n",
              "1482473                    Worn Once!!! Great condition!!!   21-6-2018     16  \n",
              "\n",
              "[6279 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# looking the categories name in original dataset\n",
        "print(train['category_name'].unique())\n",
        "print(train['category_name'].describe())\n",
        "display (train[train['category_name'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CVvHZeypojD3"
      },
      "outputs": [],
      "source": [
        "# droping null categories names and brands names(around 3000 values)\n",
        "dropnull = train[train.category_name.isnull() & train.brand_name.isnull()].index\n",
        "train = train.drop(dropnull, axis=0).reset_index() #.reset_index(drop=True) -> usar sem o drop mantém a coluna index dentro do dataframe, outra coluna = mais memoria necessária"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "s2SQm-eOqS1Q",
        "outputId": "5aa6bcfe-fd30-484a-dc38-2bd72154149f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Men/Tops/T-shirts' 'Electronics/Computers & Tablets/Components & Parts'\n",
            " 'Women/Tops & Blouses/Blouse' ... 'Handmade/Jewelry/Clothing'\n",
            " 'Vintage & Collectibles/Supplies/Ephemera' 'Handmade/Pets/Blanket']\n",
            "count                                            1476256\n",
            "unique                                              1266\n",
            "top       Women/Athletic Apparel/Pants, Tights, Leggings\n",
            "freq                                               60092\n",
            "Name: category_name, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>train_id</th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>984</td>\n",
              "      <td>984</td>\n",
              "      <td>AUTHENTIC BRWN MICHAEL KORS MAKEUP STAIN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael Kors</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>5-2-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>1185</td>\n",
              "      <td>1185</td>\n",
              "      <td>Teenage Mutant Ninja Turtle Van/ Extras</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nickelodeon</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Teenage Mutant Ninja Turtle Van, April O'Neil ...</td>\n",
              "      <td>13-4-2018</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1271</th>\n",
              "      <td>1274</td>\n",
              "      <td>1274</td>\n",
              "      <td>Black Ribbed Off-the-Shoulder Crop Top</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Urban Outfitters</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>From the silence + noise brand sold at Urban O...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1317</th>\n",
              "      <td>1320</td>\n",
              "      <td>1320</td>\n",
              "      <td>Nice Condition Pet Escort</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PetSafe</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nice condition I will wipe down before selling</td>\n",
              "      <td>10-2-2018</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1733</th>\n",
              "      <td>1739</td>\n",
              "      <td>1739</td>\n",
              "      <td>SchoolWear Uniform Pants Bugle Boy</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bugle Boy</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Selling Kids Pant celebrate the back to school...</td>\n",
              "      <td>8-8-2018</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475787</th>\n",
              "      <td>1479167</td>\n",
              "      <td>1479167</td>\n",
              "      <td>Steve Madden Black Heels</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Steve Madden</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Please look at the photos before purchasing</td>\n",
              "      <td>5-2-2018</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476717</th>\n",
              "      <td>1480098</td>\n",
              "      <td>1480098</td>\n",
              "      <td>Nike Slides *On hold*</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nike</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Worn but not a lot</td>\n",
              "      <td>8-4-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476843</th>\n",
              "      <td>1480224</td>\n",
              "      <td>1480224</td>\n",
              "      <td>2xl Amelia Lularoe</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LuLaRoe</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>New without tags. Only tried on. Only the dres...</td>\n",
              "      <td>17-8-2018</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478363</th>\n",
              "      <td>1481750</td>\n",
              "      <td>1481750</td>\n",
              "      <td>American Eagle Jeggings</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American Eagle</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Worn a couple of time Size 4</td>\n",
              "      <td>12-10-2018</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479084</th>\n",
              "      <td>1482473</td>\n",
              "      <td>1482473</td>\n",
              "      <td>Puma Suede Emboss</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PUMA</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Worn Once!!! Great condition!!!</td>\n",
              "      <td>21-6-2018</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2890 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  train_id                                      name  \\\n",
              "981          984       984  AUTHENTIC BRWN MICHAEL KORS MAKEUP STAIN   \n",
              "1182        1185      1185   Teenage Mutant Ninja Turtle Van/ Extras   \n",
              "1271        1274      1274    Black Ribbed Off-the-Shoulder Crop Top   \n",
              "1317        1320      1320                 Nice Condition Pet Escort   \n",
              "1733        1739      1739        SchoolWear Uniform Pants Bugle Boy   \n",
              "...          ...       ...                                       ...   \n",
              "1475787  1479167   1479167                  Steve Madden Black Heels   \n",
              "1476717  1480098   1480098                     Nike Slides *On hold*   \n",
              "1476843  1480224   1480224                        2xl Amelia Lularoe   \n",
              "1478363  1481750   1481750                   American Eagle Jeggings   \n",
              "1479084  1482473   1482473                         Puma Suede Emboss   \n",
              "\n",
              "         item_condition_id category_name        brand_name  price  shipping  \\\n",
              "981                      4           NaN      Michael Kors   18.0         0   \n",
              "1182                     3           NaN       Nickelodeon    9.0         0   \n",
              "1271                     2           NaN  Urban Outfitters   15.0         0   \n",
              "1317                     2           NaN           PetSafe   12.0         0   \n",
              "1733                     2           NaN         Bugle Boy    5.0         1   \n",
              "...                    ...           ...               ...    ...       ...   \n",
              "1475787                  3           NaN      Steve Madden   24.0         0   \n",
              "1476717                  3           NaN              Nike   14.0         0   \n",
              "1476843                  2           NaN           LuLaRoe   50.0         1   \n",
              "1478363                  2           NaN    American Eagle   17.0         0   \n",
              "1479084                  2           NaN              PUMA   30.0         1   \n",
              "\n",
              "                                          item_description        date  stock  \n",
              "981                                     No description yet    5-2-2018      6  \n",
              "1182     Teenage Mutant Ninja Turtle Van, April O'Neil ...   13-4-2018      9  \n",
              "1271     From the silence + noise brand sold at Urban O...   29-2-2018     13  \n",
              "1317        Nice condition I will wipe down before selling   10-2-2018     12  \n",
              "1733     Selling Kids Pant celebrate the back to school...    8-8-2018      3  \n",
              "...                                                    ...         ...    ...  \n",
              "1475787        Please look at the photos before purchasing    5-2-2018      2  \n",
              "1476717                                 Worn but not a lot    8-4-2018      1  \n",
              "1476843  New without tags. Only tried on. Only the dres...   17-8-2018     32  \n",
              "1478363                       Worn a couple of time Size 4  12-10-2018      5  \n",
              "1479084                    Worn Once!!! Great condition!!!   21-6-2018     16  \n",
              "\n",
              "[2890 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# cheking the categories name\n",
        "print(train['category_name'].unique())\n",
        "print(train['category_name'].describe())\n",
        "display (train[train['category_name'].isnull()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbtbtL_Z1zVa"
      },
      "source": [
        "Antes tinhamos 6327 categorias nulas, agora temos 2870. As outras irei substituir por \"Other\" que já temos outras 54003 vezes utilizados no dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7VzwvRXMrZBI"
      },
      "outputs": [],
      "source": [
        "# replace null values to \"Other\" \n",
        "train['category_name'] = train['category_name'].fillna(\"Other\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gudctjb0sTc4",
        "outputId": "477fac24-2030-4b2d-ad87-3178458cbfd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1479146 entries, 0 to 1479145\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   index              1479146 non-null  int64  \n",
            " 1   train_id           1479146 non-null  int64  \n",
            " 2   name               1479146 non-null  object \n",
            " 3   item_condition_id  1479146 non-null  int64  \n",
            " 4   category_name      1479146 non-null  object \n",
            " 5   brand_name         850368 non-null   object \n",
            " 6   price              1479146 non-null  float64\n",
            " 7   shipping           1479146 non-null  int64  \n",
            " 8   item_description   1479142 non-null  object \n",
            " 9   date               1479146 non-null  object \n",
            " 10  stock              1479146 non-null  int64  \n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 124.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "hfMzwv300wp-",
        "outputId": "fc410be1-a959-48f0-a5a9-82e1b061f780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['No description yet'\n",
            " 'This keyboard is in great condition and works like it came out of the box. All of the ports are tested and work perfectly. The lights are customizable via the Razer Synapse app on your PC.'\n",
            " 'Adorable top with a hint of lace and a key hole in the back! The pale pink is a 1X, and I also have a 3X available in white!'\n",
            " ... 'Used once or twice, still in great shape.'\n",
            " 'There is 2 of each one that you see! So 2 red 2 orange and 2 of the big red and orange ones! They are from world market!'\n",
            " 'New with tag, red with sparkle. Firm price, no free shipping.']\n",
            "count                1479142\n",
            "unique               1028580\n",
            "top       No description yet\n",
            "freq                   81895\n",
            "Name: item_description, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>train_id</th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>510332</th>\n",
              "      <td>511535</td>\n",
              "      <td>511535</td>\n",
              "      <td>Shoes for Michelle</td>\n",
              "      <td>4</td>\n",
              "      <td>Kids/Girls 0-24 Mos/Shoes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5-11-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806172</th>\n",
              "      <td>808042</td>\n",
              "      <td>511535</td>\n",
              "      <td>Shoes for Michelle</td>\n",
              "      <td>4</td>\n",
              "      <td>Kids/Girls 0-24 Mos/Shoes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5-11-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1222139</th>\n",
              "      <td>1224924</td>\n",
              "      <td>1224924</td>\n",
              "      <td>Disney Minnie Head band</td>\n",
              "      <td>3</td>\n",
              "      <td>Women/Women's Accessories/Hair Accessories</td>\n",
              "      <td>Disney</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18-9-2018</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261364</th>\n",
              "      <td>1264242</td>\n",
              "      <td>1264242</td>\n",
              "      <td>For Bianca</td>\n",
              "      <td>3</td>\n",
              "      <td>Women/Women's Accessories/Scarves &amp; Wraps</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4-8-2018</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  train_id                     name  item_condition_id  \\\n",
              "510332    511535    511535       Shoes for Michelle                  4   \n",
              "806172    808042    511535       Shoes for Michelle                  4   \n",
              "1222139  1224924   1224924  Disney Minnie Head band                  3   \n",
              "1261364  1264242   1264242               For Bianca                  3   \n",
              "\n",
              "                                      category_name brand_name  price  \\\n",
              "510332                    Kids/Girls 0-24 Mos/Shoes        NaN    9.0   \n",
              "806172                    Kids/Girls 0-24 Mos/Shoes        NaN    9.0   \n",
              "1222139  Women/Women's Accessories/Hair Accessories     Disney    9.0   \n",
              "1261364   Women/Women's Accessories/Scarves & Wraps        NaN   10.0   \n",
              "\n",
              "         shipping item_description       date  stock  \n",
              "510332          0              NaN  5-11-2018      6  \n",
              "806172          0              NaN  5-11-2018      6  \n",
              "1222139         0              NaN  18-9-2018      5  \n",
              "1261364         1              NaN   4-8-2018      7  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# looking the item_description in original dataset\n",
        "print(train['item_description'].unique())\n",
        "print(train['item_description'].describe())\n",
        "display (train[train['item_description'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N1wNZ0-p1AEr"
      },
      "outputs": [],
      "source": [
        "#have just 4 lines of null item description, i will remove them\n",
        "train = train.dropna(subset = ['item_description']).reset_index()\n",
        "train = train.drop(columns = ['level_0','index','train_id','shipping'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p0mbbLmtoGv"
      },
      "source": [
        "Sobre o Shipping acredito que não vale a pena manter, ele mostra somente por quem a taxa de envio foi paga, não intefere no preço."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "BL95pfWd6RC1",
        "outputId": "74abe0d5-7c57-4fc4-dcd3-548497a7c0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nan 'Razer' 'Target' ... 'Tasso Elba' 'Camilia' 'Dark Horse']\n",
            "count     850367\n",
            "unique      4542\n",
            "top         PINK\n",
            "freq       54184\n",
            "Name: brand_name, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
              "      <td>3</td>\n",
              "      <td>Men/Tops/T-shirts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>17-5-2018</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Leather Horse Statues</td>\n",
              "      <td>1</td>\n",
              "      <td>Home/Home Décor/Home Décor Accents</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
              "      <td>19-2-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24K GOLD plated rose</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Jewelry/Necklaces</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Complete with certificate of authenticity</td>\n",
              "      <td>16-4-2018</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bundled items requested for Ruie</td>\n",
              "      <td>3</td>\n",
              "      <td>Women/Other/Other</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59.0</td>\n",
              "      <td>Banana republic bottoms, Candies skirt with ma...</td>\n",
              "      <td>8-11-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Porcelain clown doll checker pants VTG</td>\n",
              "      <td>3</td>\n",
              "      <td>Vintage &amp; Collectibles/Collectibles/Doll</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>I realized his pants are on backwards after th...</td>\n",
              "      <td>20-6-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479133</th>\n",
              "      <td>Harry Potter Shirt! Women M/ Girl XL</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Tops &amp; Blouses/T-Shirts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Great Harry Potter Shirt! \"Hogwarts, School of...</td>\n",
              "      <td>24-12-2018</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479134</th>\n",
              "      <td>Blk/white ribbed mock neck bodysuit M</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Brand new black and white ribbed mock neck bod...</td>\n",
              "      <td>15-9-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479139</th>\n",
              "      <td>21 day fix containers and eating plan</td>\n",
              "      <td>2</td>\n",
              "      <td>Sports &amp; Outdoors/Exercise/Fitness accessories</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Used once or twice, still in great shape.</td>\n",
              "      <td>6-8-2018</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479140</th>\n",
              "      <td>World markets lanterns</td>\n",
              "      <td>3</td>\n",
              "      <td>Home/Home Décor/Home Décor Accents</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>There is 2 of each one that you see! So 2 red ...</td>\n",
              "      <td>12-2-2018</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479141</th>\n",
              "      <td>Brand new lux de ville wallet</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Women's Accessories/Wallets</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>New with tag, red with sparkle. Firm price, no...</td>\n",
              "      <td>28-11-2018</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>628775 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           name  item_condition_id  \\\n",
              "0           MLB Cincinnati Reds T Shirt Size XL                  3   \n",
              "3                         Leather Horse Statues                  1   \n",
              "4                          24K GOLD plated rose                  1   \n",
              "5              Bundled items requested for Ruie                  3   \n",
              "9        Porcelain clown doll checker pants VTG                  3   \n",
              "...                                         ...                ...   \n",
              "1479133    Harry Potter Shirt! Women M/ Girl XL                  2   \n",
              "1479134   Blk/white ribbed mock neck bodysuit M                  1   \n",
              "1479139   21 day fix containers and eating plan                  2   \n",
              "1479140                  World markets lanterns                  3   \n",
              "1479141           Brand new lux de ville wallet                  1   \n",
              "\n",
              "                                          category_name brand_name  price  \\\n",
              "0                                     Men/Tops/T-shirts        NaN   10.0   \n",
              "3                    Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
              "4                               Women/Jewelry/Necklaces        NaN   44.0   \n",
              "5                                     Women/Other/Other        NaN   59.0   \n",
              "9              Vintage & Collectibles/Collectibles/Doll        NaN    8.0   \n",
              "...                                                 ...        ...    ...   \n",
              "1479133                   Women/Tops & Blouses/T-Shirts        NaN   12.0   \n",
              "1479134                     Women/Tops & Blouses/Blouse        NaN   10.0   \n",
              "1479139  Sports & Outdoors/Exercise/Fitness accessories        NaN   12.0   \n",
              "1479140              Home/Home Décor/Home Décor Accents        NaN   45.0   \n",
              "1479141               Women/Women's Accessories/Wallets        NaN   22.0   \n",
              "\n",
              "                                          item_description        date  stock  \n",
              "0                                       No description yet   17-5-2018     27  \n",
              "3        New with tags. Leather horses. Retail for [rm]...   19-2-2018      1  \n",
              "4                Complete with certificate of authenticity   16-4-2018     13  \n",
              "5        Banana republic bottoms, Candies skirt with ma...   8-11-2018      6  \n",
              "9        I realized his pants are on backwards after th...   20-6-2018      1  \n",
              "...                                                    ...         ...    ...  \n",
              "1479133  Great Harry Potter Shirt! \"Hogwarts, School of...  24-12-2018      5  \n",
              "1479134  Brand new black and white ribbed mock neck bod...   15-9-2018      1  \n",
              "1479139          Used once or twice, still in great shape.    6-8-2018     15  \n",
              "1479140  There is 2 of each one that you see! So 2 red ...   12-2-2018     20  \n",
              "1479141  New with tag, red with sparkle. Firm price, no...  28-11-2018      9  \n",
              "\n",
              "[628775 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# looking the brands name in original dataset\n",
        "print(train['brand_name'].unique())\n",
        "print(train['brand_name'].describe())\n",
        "display (train[train['brand_name'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3VSzPCie7CQD",
        "outputId": "dee7c5f4-a50c-42da-81e7-8d2ff6d9c65b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>Lego Harry Potter Years 1-4 Wii</td>\n",
              "      <td>2</td>\n",
              "      <td>Electronics/Video Games &amp; Consoles/Games</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Lego Harry Potter Years 1-4 Wii E10+ Warner Br...</td>\n",
              "      <td>7-1-2018</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>Harry Potter PC game free shipping</td>\n",
              "      <td>3</td>\n",
              "      <td>Electronics/Video Games &amp; Consoles/Games</td>\n",
              "      <td>Microsoft</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Works great Fast shipping with tracking Weighs...</td>\n",
              "      <td>11-5-2018</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3747</th>\n",
              "      <td>Lularoe TC Harry Potter Owls Blue</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Brand new. Harry Potter Owl. Extremely hard to...</td>\n",
              "      <td>17-2-2018</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4200</th>\n",
              "      <td>Harry Potter wands</td>\n",
              "      <td>2</td>\n",
              "      <td>Vintage &amp; Collectibles/Collectibles/Souvenir</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Like new. No flaws. Snape and mad eye</td>\n",
              "      <td>12-11-2018</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5058</th>\n",
              "      <td>Nintendo Wii game Harry Potter</td>\n",
              "      <td>2</td>\n",
              "      <td>Vintage &amp; Collectibles/Electronics/Video Game</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Like new</td>\n",
              "      <td>19-1-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476503</th>\n",
              "      <td>Harry Potter - Gryffindor Sport Shirt</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Tops &amp; Blouses/T-Shirts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Size small. Excellent condition; bought from U...</td>\n",
              "      <td>3-10-2018</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477329</th>\n",
              "      <td>Harry Potter Books Case - Snap On</td>\n",
              "      <td>2</td>\n",
              "      <td>Electronics/Cell Phones &amp; Accessories/Cases, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>FREE SHIPPING! This iPhone 6 case is a snap on...</td>\n",
              "      <td>21-10-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477397</th>\n",
              "      <td>5 Harry Potter Bertie Botts</td>\n",
              "      <td>1</td>\n",
              "      <td>Other/Books/Literature &amp; Fiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Sealed. left over from HP party. Exp feb 2018</td>\n",
              "      <td>7-7-2018</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478850</th>\n",
              "      <td>FREESHIPPING! Harry Potter Mystery Mini</td>\n",
              "      <td>2</td>\n",
              "      <td>Kids/Toys/Action Figures &amp; Statues</td>\n",
              "      <td>Funko</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Harry Potter Mystery Mini, Barnes &amp; Noble Excl...</td>\n",
              "      <td>26-10-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479133</th>\n",
              "      <td>Harry Potter Shirt! Women M/ Girl XL</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Tops &amp; Blouses/T-Shirts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Great Harry Potter Shirt! \"Hogwarts, School of...</td>\n",
              "      <td>24-12-2018</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1296 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            name  item_condition_id  \\\n",
              "235              Lego Harry Potter Years 1-4 Wii                  2   \n",
              "756           Harry Potter PC game free shipping                  3   \n",
              "3747           Lularoe TC Harry Potter Owls Blue                  1   \n",
              "4200                          Harry Potter wands                  2   \n",
              "5058              Nintendo Wii game Harry Potter                  2   \n",
              "...                                          ...                ...   \n",
              "1476503    Harry Potter - Gryffindor Sport Shirt                  1   \n",
              "1477329        Harry Potter Books Case - Snap On                  2   \n",
              "1477397              5 Harry Potter Bertie Botts                  1   \n",
              "1478850  FREESHIPPING! Harry Potter Mystery Mini                  2   \n",
              "1479133     Harry Potter Shirt! Women M/ Girl XL                  2   \n",
              "\n",
              "                                             category_name brand_name  price  \\\n",
              "235               Electronics/Video Games & Consoles/Games   Nintendo   19.0   \n",
              "756               Electronics/Video Games & Consoles/Games  Microsoft    6.0   \n",
              "3747        Women/Athletic Apparel/Pants, Tights, Leggings        NaN   60.0   \n",
              "4200          Vintage & Collectibles/Collectibles/Souvenir        NaN   50.0   \n",
              "5058         Vintage & Collectibles/Electronics/Video Game   Nintendo   11.0   \n",
              "...                                                    ...        ...    ...   \n",
              "1476503                      Women/Tops & Blouses/T-Shirts        NaN   14.0   \n",
              "1477329  Electronics/Cell Phones & Accessories/Cases, C...        NaN    6.0   \n",
              "1477397                   Other/Books/Literature & Fiction        NaN   19.0   \n",
              "1478850                 Kids/Toys/Action Figures & Statues      Funko   12.0   \n",
              "1479133                      Women/Tops & Blouses/T-Shirts        NaN   12.0   \n",
              "\n",
              "                                          item_description        date  stock  \n",
              "235      Lego Harry Potter Years 1-4 Wii E10+ Warner Br...    7-1-2018      8  \n",
              "756      Works great Fast shipping with tracking Weighs...   11-5-2018      9  \n",
              "3747     Brand new. Harry Potter Owl. Extremely hard to...   17-2-2018     18  \n",
              "4200                 Like new. No flaws. Snape and mad eye  12-11-2018      9  \n",
              "5058                                              Like new   19-1-2018      1  \n",
              "...                                                    ...         ...    ...  \n",
              "1476503  Size small. Excellent condition; bought from U...   3-10-2018     37  \n",
              "1477329  FREE SHIPPING! This iPhone 6 case is a snap on...  21-10-2018      1  \n",
              "1477397      Sealed. left over from HP party. Exp feb 2018    7-7-2018      6  \n",
              "1478850  Harry Potter Mystery Mini, Barnes & Noble Excl...  26-10-2018      1  \n",
              "1479133  Great Harry Potter Shirt! \"Hogwarts, School of...  24-12-2018      5  \n",
              "\n",
              "[1296 rows x 8 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#code looking for any word or sentence in dataset\n",
        "#Augusto - colocação interessante, a gente pode definir melhor esse código, pode surgir até como um sistema de recomendação\n",
        "train[train['name'].str.find('Harry Potter')!=-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xBy6kFV62_hI"
      },
      "outputs": [],
      "source": [
        "#I will raplace all 629225 null values in \"train['brand_name']\" for other again, after we can looking again\n",
        "#Augusto - Gosto mais dessa ideia, manter esses dados melhora o algoritmo de machine learning\n",
        "train['brand_name'] = train['brand_name'].fillna(\"Other\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "brand_name\n",
              "Other                          628775\n",
              "PINK                            54184\n",
              "Nike                            53796\n",
              "Victoria's Secret               48243\n",
              "LuLaRoe                         30987\n",
              "                                ...  \n",
              "Hugga Bebe                          1\n",
              "Sarah Spencer                       1\n",
              "American Rebel Boot Company         1\n",
              "Huggies Little Swimmers             1\n",
              "wallis                              1\n",
              "Length: 4543, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.value_counts('brand_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4TaIBgZZ3X_B"
      },
      "outputs": [],
      "source": [
        "#we can also remove all this null values, but we lost 629225 lines\n",
        "\n",
        "#train['brand_name'] = train['brand_name'].dropna() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp-As3lf3VMt",
        "outputId": "5d50824d-15ba-4473-96ac-e0a6dff7965b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1479142 entries, 0 to 1479141\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   name               1479142 non-null  object \n",
            " 1   item_condition_id  1479142 non-null  int64  \n",
            " 2   category_name      1479142 non-null  object \n",
            " 3   brand_name         1479142 non-null  object \n",
            " 4   price              1479142 non-null  float64\n",
            " 5   item_description   1479142 non-null  object \n",
            " 6   date               1479142 non-null  object \n",
            " 7   stock              1479142 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 90.3+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MgHHktPft1pM",
        "outputId": "baabc785-820b-42cd-afd8-4ab9b423486f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['17-5-2018' '17-3-2018' '24-10-2018' '19-2-2018' '16-4-2018' '8-11-2018'\n",
            " '29-1-2018' '25-7-2018' '12-4-2018' '20-6-2018' '20-8-2018' '4-9-2018'\n",
            " '29-11-2018' '18-1-2018' '1-2-2018' '28-4-2018' '11-10-2018' '10-7-2018'\n",
            " '13-1-2018' '17-10-2018' '5-3-2018' '12-1-2018' '15-9-2018' '25-2-2018'\n",
            " '18-2-2018' '23-2-2018' '5-9-2018' '28-5-2018' '13-3-2018' '8-7-2018'\n",
            " '6-2-2018' '14-2-2018' '19-10-2018' '23-6-2018' '11-5-2018' '1-8-2018'\n",
            " '10-4-2018' '3-5-2018' '26-8-2018' '8-6-2018' '27-6-2018' '15-6-2018'\n",
            " '12-5-2018' '17-6-2018' '15-2-2018' '13-11-2018' '1-6-2018' '2-2-2018'\n",
            " '4-5-2018' '29-6-2018' '14-5-2018' '15-5-2018' '22-10-2018' '21-5-2018'\n",
            " '19-11-2018' '18-8-2018' '19-7-2018' '25-6-2018' '24-11-2018'\n",
            " '13-10-2018' '21-10-2018' '2-11-2018' '23-11-2018' '29-4-2018'\n",
            " '20-2-2018' '18-11-2018' '6-4-2018' '3-3-2018' '7-2-2018' '29-10-2018'\n",
            " '14-9-2018' '21-6-2018' '13-8-2018' '11-7-2018' '19-3-2018' '18-10-2018'\n",
            " '3-1-2018' '23-7-2018' '9-8-2018' '8-5-2018' '10-8-2018' '14-6-2018'\n",
            " '24-5-2018' '29-8-2018' '2-10-2018' '25-1-2018' '22-7-2018' '9-3-2018'\n",
            " '5-2-2018' '7-9-2018' '28-3-2018' '1-3-2018' '16-9-2018' '10-1-2018'\n",
            " '21-1-2018' '12-7-2018' '5-10-2018' '21-7-2018' '21-11-2018' '6-10-2018'\n",
            " '24-4-2018' '6-5-2018' '5-11-2018' '6-7-2018' '17-11-2018' '11-1-2018'\n",
            " '2-4-2018' '28-1-2018' '11-3-2018' '18-5-2018' '5-5-2018' '22-6-2018'\n",
            " '23-10-2018' '15-10-2018' '12-2-2018' '28-2-2018' '4-8-2018' '18-7-2018'\n",
            " '5-8-2018' '21-2-2018' '19-6-2018' '7-4-2018' '29-3-2018' '26-6-2018'\n",
            " '3-9-2018' '1-10-2018' '10-11-2018' '22-4-2018' '9-10-2018' '8-3-2018'\n",
            " '13-7-2018' '1-1-2018' '1-5-2018' '20-7-2018' '27-7-2018' '2-5-2018'\n",
            " '14-4-2018' '2-7-2018' '15-8-2018' '8-2-2018' '3-6-2018' '24-9-2018'\n",
            " '17-7-2018' '22-5-2018' '25-5-2018' '1-7-2018' '14-10-2018' '5-6-2018'\n",
            " '12-6-2018' '16-8-2018' '17-2-2018' '19-4-2018' '14-8-2018' '12-9-2018'\n",
            " '25-11-2018' '22-9-2018' '12-8-2018' '6-11-2018' '12-10-2018'\n",
            " '28-11-2018' '7-1-2018' '12-3-2018' '2-8-2018' '4-10-2018' '13-2-2018'\n",
            " '24-7-2018' '3-11-2018' '1-11-2018' '21-4-2018' '20-5-2018' '7-6-2018'\n",
            " '16-7-2018' '7-5-2018' '9-9-2018' '2-3-2018' '20-3-2018' '15-11-2018'\n",
            " '23-8-2018' '18-4-2018' '2-6-2018' '3-7-2018' '17-8-2018' '2-9-2018'\n",
            " '23-3-2018' '28-10-2018' '16-11-2018' '22-8-2018' '8-8-2018' '21-3-2018'\n",
            " '24-8-2018' '6-8-2018' '27-10-2018' '10-10-2018' '26-7-2018' '27-2-2018'\n",
            " '24-3-2018' '13-6-2018' '22-3-2018' '25-9-2018' '14-1-2018' '3-8-2018'\n",
            " '26-1-2018' '26-5-2018' '17-4-2018' '18-6-2018' '9-4-2018' '29-2-2018'\n",
            " '1-9-2018' '23-4-2018' '26-2-2018' '27-8-2018' '20-1-2018' '27-9-2018'\n",
            " '9-11-2018' '19-9-2018' '8-9-2018' '20-4-2018' '10-6-2018' '27-5-2018'\n",
            " '14-3-2018' '8-4-2018' '3-10-2018' '10-3-2018' '6-1-2018' '17-1-2018'\n",
            " '14-11-2018' '26-10-2018' '7-7-2018' '6-9-2018' '24-6-2018' '28-8-2018'\n",
            " '24-2-2018' '27-4-2018' '23-1-2018' '25-4-2018' '15-7-2018' '25-8-2018'\n",
            " '10-2-2018' '11-4-2018' '22-11-2018' '16-10-2018' '11-8-2018'\n",
            " '12-11-2018' '29-5-2018' '11-2-2018' '25-3-2018' '23-5-2018' '8-1-2018'\n",
            " '13-5-2018' '4-4-2018' '25-10-2018' '13-4-2018' '22-1-2018' '10-5-2018'\n",
            " '19-8-2018' '15-1-2018' '4-3-2018' '28-7-2018' '4-2-2018' '5-4-2018'\n",
            " '6-6-2018' '4-7-2018' '20-10-2018' '26-11-2018' '29-7-2018' '7-11-2018'\n",
            " '9-5-2018' '24-1-2018' '3-4-2018' '19-5-2018' '29-9-2018' '16-3-2018'\n",
            " '10-9-2018' '18-3-2018' '27-11-2018' '28-6-2018' '11-6-2018' '11-11-2018'\n",
            " '16-1-2018' '7-8-2018' '8-10-2018' '15-4-2018' '21-9-2018' '28-9-2018'\n",
            " '21-8-2018' '16-2-2018' '26-4-2018' '15-3-2018' '16-6-2018' '6-3-2018'\n",
            " '7-3-2018' '9-1-2018' '16-5-2018' '23-9-2018' '11-9-2018' '26-3-2018'\n",
            " '5-1-2018' '27-1-2018' '4-11-2018' '13-9-2018' '4-1-2018' '2-1-2018'\n",
            " '19-1-2018' '9-7-2018' '20-11-2018' '17-9-2018' '4-6-2018' '27-3-2018'\n",
            " '3-2-2018' '9-6-2018' '9-2-2018' '14-7-2018' '26-9-2018' '18-9-2018'\n",
            " '22-2-2018' '1-4-2018' '20-9-2018' '5-7-2018' '7-10-2018' '14-12-2018'\n",
            " '3-12-2018' '15-12-2018' '12-12-2018' '9-12-2018' '19-12-2018'\n",
            " '25-12-2018' '21-12-2018' '22-12-2018' '26-12-2018' '11-12-2018'\n",
            " '4-12-2018' '7-12-2018' '8-12-2018' '2-12-2018' '10-12-2018' '28-12-2018'\n",
            " '17-12-2018' '20-12-2018' '23-12-2018' '1-12-2018' '27-12-2018'\n",
            " '5-12-2018' '18-12-2018' '16-12-2018' '24-12-2018' '13-12-2018'\n",
            " '29-12-2018' '6-12-2018']\n",
            "count       1479142\n",
            "unique          348\n",
            "top       28-3-2018\n",
            "freq           4768\n",
            "Name: date, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [name, item_condition_id, category_name, brand_name, price, item_description, date, stock]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# looking the dates in original dataset\n",
        "print(train['date'].unique())\n",
        "print(train['date'].describe())\n",
        "display (train[train['date'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NRrj1DAsu5Q1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
          ]
        }
      ],
      "source": [
        "#Creating new dates columns\n",
        "train['date2'] = pd.to_datetime(train['date'], errors='coerce')    #corrige os erros com os valores das datas de nascimento, adequa para DateTime\n",
        "train['day'] = train['date2'].dt.day\n",
        "train['month'] = train['date2'].dt.month\n",
        "train['year'] = train['date2'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7X6xevP93LWI",
        "outputId": "53d86c42-ce21-4655-ad12-e9e7c039723b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "      <th>date2</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>LuLaRoe Halloween Frankenstein Leggings</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
              "      <td>Independent</td>\n",
              "      <td>24.0</td>\n",
              "      <td>LuLaRoe Leggings One Size Halloween Frankenste...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>5</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>New iPhone 6/6s Purple Ombre Soft Case</td>\n",
              "      <td>1</td>\n",
              "      <td>Electronics/Cell Phones &amp; Accessories/Cases, C...</td>\n",
              "      <td>Other</td>\n",
              "      <td>10.0</td>\n",
              "      <td>PRICES ARE FIRM UNLESS YOU BUNDLE! ALL OFFERS ...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1166</th>\n",
              "      <td>Rambler YETI Coffee Cups 2 PC</td>\n",
              "      <td>1</td>\n",
              "      <td>Vintage &amp; Collectibles/Serving/Mug</td>\n",
              "      <td>Other</td>\n",
              "      <td>40.0</td>\n",
              "      <td>DON'T purchases before reading following detai...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>10</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1271</th>\n",
              "      <td>Black Ribbed Off-the-Shoulder Crop Top</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>Urban Outfitters</td>\n",
              "      <td>15.0</td>\n",
              "      <td>From the silence + noise brand sold at Urban O...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>13</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1304</th>\n",
              "      <td>Active leggings</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
              "      <td>Aeropostale</td>\n",
              "      <td>21.0</td>\n",
              "      <td>There super cute but there a little see throug...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>8</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478157</th>\n",
              "      <td>BUNDLE FOR SYLVIA HERNANDEZ</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Women's Handbags/Shoulder Bag</td>\n",
              "      <td>Burberry</td>\n",
              "      <td>75.0</td>\n",
              "      <td>BURBERRY SHOULDER BAG, IN EXCELLENT CONDITION....</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478521</th>\n",
              "      <td>Kat von d shade +light eyeshadow palette</td>\n",
              "      <td>3</td>\n",
              "      <td>Beauty/Makeup/Makeup Palettes</td>\n",
              "      <td>Kat Von D</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Bought on here awhile ago one color was broken...</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>18</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478526</th>\n",
              "      <td>Vans authentic</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Shoes/Fashion Sneakers</td>\n",
              "      <td>VANS</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Red authentic vans Size men 6, women 7.5</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>3</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478533</th>\n",
              "      <td>Dr martens women pink shoes</td>\n",
              "      <td>2</td>\n",
              "      <td>Women/Shoes/Athletic</td>\n",
              "      <td>Dr. Martens</td>\n",
              "      <td>41.0</td>\n",
              "      <td>I also have a man size</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478626</th>\n",
              "      <td>Fidget spinner FREE SHIP</td>\n",
              "      <td>1</td>\n",
              "      <td>Kids/Toys/Games</td>\n",
              "      <td>Other</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Brand new Price is one per each Bundle and save</td>\n",
              "      <td>29-2-2018</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4465 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             name  item_condition_id  \\\n",
              "348       LuLaRoe Halloween Frankenstein Leggings                  2   \n",
              "991        New iPhone 6/6s Purple Ombre Soft Case                  1   \n",
              "1166                Rambler YETI Coffee Cups 2 PC                  1   \n",
              "1271       Black Ribbed Off-the-Shoulder Crop Top                  2   \n",
              "1304                              Active leggings                  2   \n",
              "...                                           ...                ...   \n",
              "1478157               BUNDLE FOR SYLVIA HERNANDEZ                  2   \n",
              "1478521  Kat von d shade +light eyeshadow palette                  3   \n",
              "1478526                            Vans authentic                  1   \n",
              "1478533               Dr martens women pink shoes                  2   \n",
              "1478626                  Fidget spinner FREE SHIP                  1   \n",
              "\n",
              "                                             category_name        brand_name  \\\n",
              "348         Women/Athletic Apparel/Pants, Tights, Leggings       Independent   \n",
              "991      Electronics/Cell Phones & Accessories/Cases, C...             Other   \n",
              "1166                    Vintage & Collectibles/Serving/Mug             Other   \n",
              "1271                                                 Other  Urban Outfitters   \n",
              "1304        Women/Athletic Apparel/Pants, Tights, Leggings       Aeropostale   \n",
              "...                                                    ...               ...   \n",
              "1478157                Women/Women's Handbags/Shoulder Bag          Burberry   \n",
              "1478521                      Beauty/Makeup/Makeup Palettes         Kat Von D   \n",
              "1478526                       Women/Shoes/Fashion Sneakers              VANS   \n",
              "1478533                               Women/Shoes/Athletic       Dr. Martens   \n",
              "1478626                                    Kids/Toys/Games             Other   \n",
              "\n",
              "         price                                   item_description       date  \\\n",
              "348       24.0  LuLaRoe Leggings One Size Halloween Frankenste...  29-2-2018   \n",
              "991       10.0  PRICES ARE FIRM UNLESS YOU BUNDLE! ALL OFFERS ...  29-2-2018   \n",
              "1166      40.0  DON'T purchases before reading following detai...  29-2-2018   \n",
              "1271      15.0  From the silence + noise brand sold at Urban O...  29-2-2018   \n",
              "1304      21.0  There super cute but there a little see throug...  29-2-2018   \n",
              "...        ...                                                ...        ...   \n",
              "1478157   75.0  BURBERRY SHOULDER BAG, IN EXCELLENT CONDITION....  29-2-2018   \n",
              "1478521   19.0  Bought on here awhile ago one color was broken...  29-2-2018   \n",
              "1478526   34.0           Red authentic vans Size men 6, women 7.5  29-2-2018   \n",
              "1478533   41.0                             I also have a man size  29-2-2018   \n",
              "1478626   16.0    Brand new Price is one per each Bundle and save  29-2-2018   \n",
              "\n",
              "         stock date2  day  month  year  \n",
              "348          5   NaT  NaN    NaN   NaN  \n",
              "991          1   NaT  NaN    NaN   NaN  \n",
              "1166        10   NaT  NaN    NaN   NaN  \n",
              "1271        13   NaT  NaN    NaN   NaN  \n",
              "1304         8   NaT  NaN    NaN   NaN  \n",
              "...        ...   ...  ...    ...   ...  \n",
              "1478157      1   NaT  NaN    NaN   NaN  \n",
              "1478521     18   NaT  NaN    NaN   NaN  \n",
              "1478526      3   NaT  NaN    NaN   NaN  \n",
              "1478533      1   NaT  NaN    NaN   NaN  \n",
              "1478626      1   NaT  NaN    NaN   NaN  \n",
              "\n",
              "[4465 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# looking the null dates\n",
        "display (train[train['date2'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "frPshbuO3ZiA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count          4465\n",
              "unique            1\n",
              "top       29-2-2018\n",
              "freq           4465\n",
              "Name: date, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_date = train[train['date2'].isnull()]\n",
        "test_date['date'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONDagoGK38IF"
      },
      "source": [
        "Todas as datas que ficaram nulas são do dia 29/02/2018. Como esse dia não existe vamos substituí-lo pelo dia 28/02/2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CxzMbboY5ctH"
      },
      "outputs": [],
      "source": [
        "#Augusto - pode fazer esse código antes da primeira coleta das datas\n",
        "train['date'] =  train['date'].replace('29-2-2018','28-2-2018')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zIvRGJBb57fk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-10-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
            "e:\\anaconda\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
            "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
          ]
        }
      ],
      "source": [
        "#refazendo as colunas para não ter valores nulos\n",
        "train['date2'] = pd.to_datetime(train['date'], errors='coerce')    #corrige os erros com os valores das datas de nascimento, adequa para DateTime\n",
        "train['day'] = train['date2'].dt.day\n",
        "train['month'] = train['date2'].dt.month\n",
        "train['year'] = train['date2'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmroRu9ewJCo",
        "outputId": "177dfad4-1823-41ef-f5e1-f83fa9be8bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1479142 entries, 0 to 1479141\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count    Dtype         \n",
            "---  ------             --------------    -----         \n",
            " 0   name               1479142 non-null  object        \n",
            " 1   item_condition_id  1479142 non-null  int64         \n",
            " 2   category_name      1479142 non-null  object        \n",
            " 3   brand_name         1479142 non-null  object        \n",
            " 4   price              1479142 non-null  float64       \n",
            " 5   item_description   1479142 non-null  object        \n",
            " 6   date               1479142 non-null  object        \n",
            " 7   stock              1479142 non-null  int64         \n",
            " 8   date2              1479142 non-null  datetime64[ns]\n",
            " 9   day                1479142 non-null  int64         \n",
            " 10  month              1479142 non-null  int64         \n",
            " 11  year               1479142 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
            "memory usage: 135.4+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fUfjT0oU6ImN",
        "outputId": "41f1a08a-19ca-44cd-c834-eeb8fad41d89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>category_name</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "      <th>date2</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
              "      <td>3</td>\n",
              "      <td>Men/Tops/T-shirts</td>\n",
              "      <td>Other</td>\n",
              "      <td>10.0</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>17-5-2018</td>\n",
              "      <td>27</td>\n",
              "      <td>2018-05-17</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
              "      <td>3</td>\n",
              "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
              "      <td>Razer</td>\n",
              "      <td>52.0</td>\n",
              "      <td>This keyboard is in great condition and works ...</td>\n",
              "      <td>17-3-2018</td>\n",
              "      <td>15</td>\n",
              "      <td>2018-03-17</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVA-VIV Blouse</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
              "      <td>Target</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
              "      <td>24-10-2018</td>\n",
              "      <td>14</td>\n",
              "      <td>2018-10-24</td>\n",
              "      <td>24</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Leather Horse Statues</td>\n",
              "      <td>1</td>\n",
              "      <td>Home/Home Décor/Home Décor Accents</td>\n",
              "      <td>Other</td>\n",
              "      <td>35.0</td>\n",
              "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
              "      <td>19-2-2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24K GOLD plated rose</td>\n",
              "      <td>1</td>\n",
              "      <td>Women/Jewelry/Necklaces</td>\n",
              "      <td>Other</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Complete with certificate of authenticity</td>\n",
              "      <td>16-4-2018</td>\n",
              "      <td>13</td>\n",
              "      <td>2018-04-16</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  name  item_condition_id  \\\n",
              "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
              "1     Razer BlackWidow Chroma Keyboard                  3   \n",
              "2                       AVA-VIV Blouse                  1   \n",
              "3                Leather Horse Statues                  1   \n",
              "4                 24K GOLD plated rose                  1   \n",
              "\n",
              "                                       category_name brand_name  price  \\\n",
              "0                                  Men/Tops/T-shirts      Other   10.0   \n",
              "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
              "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
              "3                 Home/Home Décor/Home Décor Accents      Other   35.0   \n",
              "4                            Women/Jewelry/Necklaces      Other   44.0   \n",
              "\n",
              "                                    item_description        date  stock  \\\n",
              "0                                 No description yet   17-5-2018     27   \n",
              "1  This keyboard is in great condition and works ...   17-3-2018     15   \n",
              "2  Adorable top with a hint of lace and a key hol...  24-10-2018     14   \n",
              "3  New with tags. Leather horses. Retail for [rm]...   19-2-2018      1   \n",
              "4          Complete with certificate of authenticity   16-4-2018     13   \n",
              "\n",
              "       date2  day  month  year  \n",
              "0 2018-05-17   17      5  2018  \n",
              "1 2018-03-17   17      3  2018  \n",
              "2 2018-10-24   24     10  2018  \n",
              "3 2018-02-19   19      2  2018  \n",
              "4 2018-04-16   16      4  2018  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#A function that takes in a dataframe and a column name as parameters.\n",
        "#It then queries the dataframe for rows where the column value is 0. \n",
        "#It then drops those rows from the dataframe and returns the dataframe.\n",
        "def clear_price0(dataframe,column):\n",
        "    x = dataframe.query(f'{column} == 0').index\n",
        "    dataframe.drop(x, inplace= True)\n",
        "    return dataframe\n",
        "train = clear_price0(train,'price')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
